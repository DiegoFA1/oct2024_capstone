{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ae3328c-142a-47d5-81a4-40a44591cc8e",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e06e413c-7e65-4034-9ff8-c88300168973",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "491c1cec-3bfc-452d-8ade-64654891cf1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/PostBooksEDA.csv', index_col=0)\n",
    "df_encoded = pd.read_csv('../data/PostEncodedBooksEDA.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4218ccd0-facd-43ea-9582-8de309c5c143",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded = df_encoded.drop(columns=['user_id','isbn'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1759be2f-fae1-4f3e-83a9-d5b35e8d58b3",
   "metadata": {},
   "source": [
    "For the initial models we will be building, User ID and ISBN will not be needed since they are merely identifiers and do not have meaningful relationships with the target variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c3b0a4c-d5f2-4f94-ad74-13c3af020b22",
   "metadata": {},
   "source": [
    "## Stats Logistic model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82758af0-1488-4c11-b6de-f34a11b62600",
   "metadata": {},
   "source": [
    "Since logistic models predict values between 0 and 1, we will convert the ratings into implicit (0) and explicit (1) categories to predict whether users are likely to leave a review or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f30ffad1-a912-41cc-ab72-a6557b6f071d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_encoded.drop('rating', axis=1)\n",
    "y = df_encoded['rating'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "552bd681-78fd-480d-83af-a33369014dfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['user_id', 'age', 'isbn', 'year_of_publication', 'Africa', 'Asia',\n",
       "       'Europe', 'North America', 'Oceania', 'South America',\n",
       "       'author_frequency', 'author_implicit_encoded',\n",
       "       'author_explicit_encoded', 'author_avg_all_reviews',\n",
       "       'publisher_frequency', 'publisher_implicit_encoded',\n",
       "       'publisher_explicit_encoded', 'publisher_avg_all_reviews', 'de', 'en',\n",
       "       'es', 'fr', 'it', 'unknown_lg', 'art & culture', 'business & economics',\n",
       "       'children's books', 'cookbooks', 'fiction', 'health & fitness',\n",
       "       'non-fiction', 'poetry', 'religion & spirituality',\n",
       "       'science & technology', 'self-help', 'unknown_category'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1b7f1070-5831-4325-a49f-b32659247706",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.apply(lambda x: 1 if 1 <= x <= 10 else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4536e200-21d1-48c8-8622-a98308d4e0e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          0\n",
       "1          1\n",
       "2          0\n",
       "4          0\n",
       "5          1\n",
       "          ..\n",
       "1031170    0\n",
       "1031171    1\n",
       "1031172    1\n",
       "1031173    1\n",
       "1031174    1\n",
       "Name: rating, Length: 978859, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d6b44f97-7b7d-4679-9e43-ea69e5bd174c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.573486\n",
      "         Iterations 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>rating</td>      <th>  No. Observations:  </th>   <td>978859</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>Logit</td>      <th>  Df Residuals:      </th>   <td>978827</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>   <td>    31</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Thu, 21 Nov 2024</td> <th>  Pseudo R-squ.:     </th>   <td>0.1265</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>23:23:01</td>     <th>  Log-Likelihood:    </th> <td>-5.6136e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>             <td>True</td>       <th>  LL-Null:           </th> <td>-6.4268e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th>   <td> 0.000</td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "               <td></td>                 <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>                      <td>   -3.7907</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>age</th>                        <td>   -0.0011</td> <td>    0.000</td> <td>   -4.825</td> <td> 0.000</td> <td>   -0.002</td> <td>   -0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>year_of_publication</th>        <td>    0.0049</td> <td>    0.000</td> <td>   14.907</td> <td> 0.000</td> <td>    0.004</td> <td>    0.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Africa</th>                     <td>   -0.1527</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Asia</th>                       <td>   -0.6341</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Europe</th>                     <td>   -0.8208</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>North America</th>              <td>   -0.8469</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Oceania</th>                    <td>   -0.9085</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>South America</th>              <td>   -0.4277</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>author_frequency</th>           <td> 5.562e-06</td> <td> 1.49e-06</td> <td>    3.722</td> <td> 0.000</td> <td> 2.63e-06</td> <td> 8.49e-06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>author_implicit_encoded</th>    <td>   -5.0709</td> <td>    0.120</td> <td>  -42.285</td> <td> 0.000</td> <td>   -5.306</td> <td>   -4.836</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>author_explicit_encoded</th>    <td>   -0.0504</td> <td>    0.007</td> <td>   -7.165</td> <td> 0.000</td> <td>   -0.064</td> <td>   -0.037</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>author_avg_all_reviews</th>     <td>    0.0323</td> <td>    0.016</td> <td>    2.061</td> <td> 0.039</td> <td>    0.002</td> <td>    0.063</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>publisher_frequency</th>        <td>  3.54e-06</td> <td> 2.51e-07</td> <td>   14.084</td> <td> 0.000</td> <td> 3.05e-06</td> <td> 4.03e-06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>publisher_implicit_encoded</th> <td>   -1.2668</td> <td>    0.250</td> <td>   -5.070</td> <td> 0.000</td> <td>   -1.756</td> <td>   -0.777</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>publisher_explicit_encoded</th> <td>   -0.1058</td> <td>    0.014</td> <td>   -7.325</td> <td> 0.000</td> <td>   -0.134</td> <td>   -0.077</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>publisher_avg_all_reviews</th>  <td>    0.0667</td> <td>    0.033</td> <td>    2.035</td> <td> 0.042</td> <td>    0.002</td> <td>    0.131</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>de</th>                         <td>   -0.6272</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en</th>                         <td>   -0.5497</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>es</th>                         <td>   -0.5842</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>fr</th>                         <td>   -0.6744</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>it</th>                         <td>   -0.8564</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>unknown_lg</th>                 <td>   -0.4988</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>art & culture</th>              <td>   -0.2947</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>business & economics</th>       <td>   -0.3799</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>children's books</th>           <td>   -0.2753</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cookbooks</th>                  <td>   -0.3033</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>fiction</th>                    <td>   -0.2540</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>health & fitness</th>           <td>   -0.2377</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>non-fiction</th>                <td>   -0.3402</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>poetry</th>                     <td>   -0.2921</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>religion & spirituality</th>    <td>   -0.3311</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>science & technology</th>       <td>   -0.3832</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>self-help</th>                  <td>   -0.3510</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>unknown_category</th>           <td>   -0.3481</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}               &      rating      & \\textbf{  No. Observations:  } &    978859    \\\\\n",
       "\\textbf{Model:}                       &      Logit       & \\textbf{  Df Residuals:      } &    978827    \\\\\n",
       "\\textbf{Method:}                      &       MLE        & \\textbf{  Df Model:          } &        31    \\\\\n",
       "\\textbf{Date:}                        & Thu, 21 Nov 2024 & \\textbf{  Pseudo R-squ.:     } &    0.1265    \\\\\n",
       "\\textbf{Time:}                        &     23:23:01     & \\textbf{  Log-Likelihood:    } & -5.6136e+05  \\\\\n",
       "\\textbf{converged:}                   &       True       & \\textbf{  LL-Null:           } & -6.4268e+05  \\\\\n",
       "\\textbf{Covariance Type:}             &    nonrobust     & \\textbf{  LLR p-value:       } &     0.000    \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                                      & \\textbf{coef} & \\textbf{std err} & \\textbf{z} & \\textbf{P$> |$z$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{const}                        &      -3.7907  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{age}                          &      -0.0011  &        0.000     &    -4.825  &         0.000        &       -0.002    &       -0.001     \\\\\n",
       "\\textbf{year\\_of\\_publication}        &       0.0049  &        0.000     &    14.907  &         0.000        &        0.004    &        0.006     \\\\\n",
       "\\textbf{Africa}                       &      -0.1527  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{Asia}                         &      -0.6341  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{Europe}                       &      -0.8208  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{North America}                &      -0.8469  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{Oceania}                      &      -0.9085  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{South America}                &      -0.4277  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{author\\_frequency}            &    5.562e-06  &     1.49e-06     &     3.722  &         0.000        &     2.63e-06    &     8.49e-06     \\\\\n",
       "\\textbf{author\\_implicit\\_encoded}    &      -5.0709  &        0.120     &   -42.285  &         0.000        &       -5.306    &       -4.836     \\\\\n",
       "\\textbf{author\\_explicit\\_encoded}    &      -0.0504  &        0.007     &    -7.165  &         0.000        &       -0.064    &       -0.037     \\\\\n",
       "\\textbf{author\\_avg\\_all\\_reviews}    &       0.0323  &        0.016     &     2.061  &         0.039        &        0.002    &        0.063     \\\\\n",
       "\\textbf{publisher\\_frequency}         &     3.54e-06  &     2.51e-07     &    14.084  &         0.000        &     3.05e-06    &     4.03e-06     \\\\\n",
       "\\textbf{publisher\\_implicit\\_encoded} &      -1.2668  &        0.250     &    -5.070  &         0.000        &       -1.756    &       -0.777     \\\\\n",
       "\\textbf{publisher\\_explicit\\_encoded} &      -0.1058  &        0.014     &    -7.325  &         0.000        &       -0.134    &       -0.077     \\\\\n",
       "\\textbf{publisher\\_avg\\_all\\_reviews} &       0.0667  &        0.033     &     2.035  &         0.042        &        0.002    &        0.131     \\\\\n",
       "\\textbf{de}                           &      -0.6272  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{en}                           &      -0.5497  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{es}                           &      -0.5842  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{fr}                           &      -0.6744  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{it}                           &      -0.8564  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{unknown\\_lg}                  &      -0.4988  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{art \\& culture}               &      -0.2947  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{business \\& economics}        &      -0.3799  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{children's books}             &      -0.2753  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{cookbooks}                    &      -0.3033  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{fiction}                      &      -0.2540  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{health \\& fitness}            &      -0.2377  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{non-fiction}                  &      -0.3402  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{poetry}                       &      -0.2921  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{religion \\& spirituality}     &      -0.3311  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{science \\& technology}        &      -0.3832  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{self-help}                    &      -0.3510  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{unknown\\_category}            &      -0.3481  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{Logit Regression Results}\n",
       "\\end{center}"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:                 rating   No. Observations:               978859\n",
       "Model:                          Logit   Df Residuals:                   978827\n",
       "Method:                           MLE   Df Model:                           31\n",
       "Date:                Thu, 21 Nov 2024   Pseudo R-squ.:                  0.1265\n",
       "Time:                        23:23:01   Log-Likelihood:            -5.6136e+05\n",
       "converged:                       True   LL-Null:                   -6.4268e+05\n",
       "Covariance Type:            nonrobust   LLR p-value:                     0.000\n",
       "==============================================================================================\n",
       "                                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "----------------------------------------------------------------------------------------------\n",
       "const                         -3.7907        nan        nan        nan         nan         nan\n",
       "age                           -0.0011      0.000     -4.825      0.000      -0.002      -0.001\n",
       "year_of_publication            0.0049      0.000     14.907      0.000       0.004       0.006\n",
       "Africa                        -0.1527        nan        nan        nan         nan         nan\n",
       "Asia                          -0.6341        nan        nan        nan         nan         nan\n",
       "Europe                        -0.8208        nan        nan        nan         nan         nan\n",
       "North America                 -0.8469        nan        nan        nan         nan         nan\n",
       "Oceania                       -0.9085        nan        nan        nan         nan         nan\n",
       "South America                 -0.4277        nan        nan        nan         nan         nan\n",
       "author_frequency            5.562e-06   1.49e-06      3.722      0.000    2.63e-06    8.49e-06\n",
       "author_implicit_encoded       -5.0709      0.120    -42.285      0.000      -5.306      -4.836\n",
       "author_explicit_encoded       -0.0504      0.007     -7.165      0.000      -0.064      -0.037\n",
       "author_avg_all_reviews         0.0323      0.016      2.061      0.039       0.002       0.063\n",
       "publisher_frequency          3.54e-06   2.51e-07     14.084      0.000    3.05e-06    4.03e-06\n",
       "publisher_implicit_encoded    -1.2668      0.250     -5.070      0.000      -1.756      -0.777\n",
       "publisher_explicit_encoded    -0.1058      0.014     -7.325      0.000      -0.134      -0.077\n",
       "publisher_avg_all_reviews      0.0667      0.033      2.035      0.042       0.002       0.131\n",
       "de                            -0.6272        nan        nan        nan         nan         nan\n",
       "en                            -0.5497        nan        nan        nan         nan         nan\n",
       "es                            -0.5842        nan        nan        nan         nan         nan\n",
       "fr                            -0.6744        nan        nan        nan         nan         nan\n",
       "it                            -0.8564        nan        nan        nan         nan         nan\n",
       "unknown_lg                    -0.4988        nan        nan        nan         nan         nan\n",
       "art & culture                 -0.2947        nan        nan        nan         nan         nan\n",
       "business & economics          -0.3799        nan        nan        nan         nan         nan\n",
       "children's books              -0.2753        nan        nan        nan         nan         nan\n",
       "cookbooks                     -0.3033        nan        nan        nan         nan         nan\n",
       "fiction                       -0.2540        nan        nan        nan         nan         nan\n",
       "health & fitness              -0.2377        nan        nan        nan         nan         nan\n",
       "non-fiction                   -0.3402        nan        nan        nan         nan         nan\n",
       "poetry                        -0.2921        nan        nan        nan         nan         nan\n",
       "religion & spirituality       -0.3311        nan        nan        nan         nan         nan\n",
       "science & technology          -0.3832        nan        nan        nan         nan         nan\n",
       "self-help                     -0.3510        nan        nan        nan         nan         nan\n",
       "unknown_category              -0.3481        nan        nan        nan         nan         nan\n",
       "==============================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.api as sm \n",
    "\n",
    "# 0. ADD THAT CONSTANT \n",
    "X_const = sm.add_constant(X)\n",
    "\n",
    "# 1. Instatiate the model\n",
    "bank_logit = sm.Logit(y, X_const)\n",
    "\n",
    "# 2. Fit the model to the data\n",
    "bank_logit_fitted = bank_logit.fit()\n",
    "\n",
    "# 3. Look at results (Summary table)\n",
    "bank_logit_fitted.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "356cfe43-cfbb-4b15-a7bf-0fe63c7a40b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The baseline model accuracy is 68.326%\n"
     ]
    }
   ],
   "source": [
    "# Calculate soft predictions\n",
    "y_proba = bank_logit_fitted.predict(X_const)\n",
    "\n",
    "# Convert soft predictions to hard predictions 0/1 \n",
    "y_pred = np.where(y_proba >= 0.5, 1, 0)\n",
    "\n",
    "# Calculate # correct\n",
    "num_correct = (y_pred == y).sum()\n",
    "\n",
    "# Calculate the percentage accuracy\n",
    "pct_accuracy = num_correct/X.shape[0]\n",
    "\n",
    "print(f'The baseline model accuracy is {np.round(pct_accuracy*100.0, 3)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664add07-18a2-4363-9628-9dd9590f18fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb734afc-6048-4bef-a32f-e884a6da0b15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2468a10c-55ad-4d67-bef4-3f261d7a25ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstone_env",
   "language": "python",
   "name": "capstone_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
